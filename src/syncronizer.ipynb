{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07324c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigbrotr import Bigbrotr\n",
    "from event import Event\n",
    "from relay import Relay\n",
    "from relay_metadata import RelayMetadata\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70f7e87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://filter.nostr.wine over clearnet...\n",
      "Error: \n",
      "Connection closed.\n",
      "Connection closed.\n",
      "Fetched 0 events.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import time\n",
    "import websocket\n",
    "import ssl\n",
    "import socks  # Provided by PySocks\n",
    "import socket\n",
    "\n",
    "def fetch_nostr_events(url, network, start, stop):\n",
    "    # Generate a random subscription ID\n",
    "    events = []\n",
    "    sub_id = \"\" + str(int(time.time()))\n",
    "\n",
    "    # Filter to get all events between start and stop\n",
    "    req = [\n",
    "        \"REQ\",\n",
    "        sub_id,\n",
    "        {\n",
    "            \"since\": int(start),\n",
    "            \"until\": int(stop)\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    close_req = [\"CLOSE\", sub_id]\n",
    "\n",
    "    # Configure proxy if using Tor\n",
    "    if network.lower() == \"tor\":\n",
    "        socks.set_default_proxy(socks.SOCKS5, \"127.0.0.1\", 9050)\n",
    "        socket.socket = socks.socksocket\n",
    "        sslopt = {\"cert_reqs\": ssl.CERT_NONE}\n",
    "    else:\n",
    "        sslopt = {\"cert_reqs\": ssl.CERT_REQUIRED}\n",
    "\n",
    "    def on_message(ws, message):\n",
    "        data = json.loads(message)\n",
    "        if data[0] == \"EVENT\":\n",
    "            try:\n",
    "                Event.from_dict(data[2])\n",
    "            except Exception as e:\n",
    "                print(e, data[2])\n",
    "            events.append(data[2])\n",
    "        elif data[0] == \"EOSE\":\n",
    "            print(\"End of stored events.\")\n",
    "            ws.send(json.dumps(close_req))\n",
    "            ws.close()\n",
    "\n",
    "    def on_error(ws, error):\n",
    "        print(\"Error:\", error)\n",
    "\n",
    "    def on_close(ws, close_status_code, close_msg):\n",
    "        print(\"Connection closed.\")\n",
    "\n",
    "\n",
    "    def on_open(ws):\n",
    "        ws.send(json.dumps(req))\n",
    "\n",
    "    print(f\"Connecting to {url} over {network}...\")\n",
    "    ws = websocket.WebSocketApp(\n",
    "        url,\n",
    "        on_message=on_message,\n",
    "        on_error=on_error,\n",
    "        on_close=on_close,\n",
    "        on_open=on_open\n",
    "    )\n",
    "\n",
    "    ws.run_forever(sslopt=sslopt)\n",
    "    print(\"Connection closed.\")\n",
    "    print(f\"Fetched {len(events)} events.\")\n",
    "    return events\n",
    "\n",
    "# Example usage:\n",
    "events = fetch_nostr_events(\"wss://filter.nostr.wine\", \"clearnet\", 1747296164-100, 1747296164)\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5525e4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Event(id=05863177df7b8764ee374a0c9f3cafb2ae6ca96dd0f10701d90a1f7f66ae6a19, pubkey=1ac0c5ab27cf0468f535805e03578fcfa52d839f8909578776a0391d77ca82f9, created_at=1746924449, kind=6, tags=[['e', 'b4d4e1de25919c3ce4f9ab6f60653cb9d819bc001c04a43d359f59bc2de2db6f'], ['p', 'b1e1185884a6d14bbfce3899cb53e8183adde642f264d0ff4f1745371e06134c']], content={\"id\":\"b4d4e1de25919c3ce4f9ab6f60653cb9d819bc001c04a43d359f59bc2de2db6f\",\"pubkey\":\"b1e1185884a6d14bbfce3899cb53e8183adde642f264d0ff4f1745371e06134c\",\"created_at\":1746921626,\"kind\":1,\"tags\":[[\"imeta\",\"url https://blossom.primal.net/dc075c32768e15be88d1d7dc300f0a5c940ca0530bd61a6a646c7ae7e506c925.jpg\",\"m image/jpeg\",\"ox dc075c32768e15be88d1d7dc300f0a5c940ca0530bd61a6a646c7ae7e506c925\",\"dim 1440x1900\"]],\"content\":\"The opportunity to own a home miner is now better than ever. 👇👇👇\\nhttps://www.solosatoshi.com/product/bitaxe-gamma/\\n\\nhttps://blossom.primal.net/dc075c32768e15be88d1d7dc300f0a5c940ca0530bd61a6a646c7ae7e506c925.jpg\",\"sig\":\"d74e1198e693355f27462a546dfe0317168682b39e6cdc89f492d3ea3b95b402a8a04a5351e36ccc88c0f969a88c07c163528910b7936c4d7be4f2216d25bc2e\"}, sig=43faea4b89464314c14135b0f09f8cbc2e3fd3858a8644d2b153548ac246005050d119e2249cd224bbc2def8876c038726e35db3dfd3d00a04a457341cefcb2f)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = {'id': '05863177df7b8764ee374a0c9f3cafb2ae6ca96dd0f10701d90a1f7f66ae6a19', 'kind': 6, 'pubkey': '1ac0c5ab27cf0468f535805e03578fcfa52d839f8909578776a0391d77ca82f9', 'created_at': 1746924449, 'content': '{\"id\":\"b4d4e1de25919c3ce4f9ab6f60653cb9d819bc001c04a43d359f59bc2de2db6f\",\"pubkey\":\"b1e1185884a6d14bbfce3899cb53e8183adde642f264d0ff4f1745371e06134c\",\"created_at\":1746921626,\"kind\":1,\"tags\":[[\"imeta\",\"url https://blossom.primal.net/dc075c32768e15be88d1d7dc300f0a5c940ca0530bd61a6a646c7ae7e506c925.jpg\",\"m image/jpeg\",\"ox dc075c32768e15be88d1d7dc300f0a5c940ca0530bd61a6a646c7ae7e506c925\",\"dim 1440x1900\"]],\"content\":\"The opportunity to own a home miner is now better than ever. 👇👇👇\\\\nhttps://www.solosatoshi.com/product/bitaxe-gamma/\\\\n\\\\nhttps://blossom.primal.net/dc075c32768e15be88d1d7dc300f0a5c940ca0530bd61a6a646c7ae7e506c925.jpg\",\"sig\":\"d74e1198e693355f27462a546dfe0317168682b39e6cdc89f492d3ea3b95b402a8a04a5351e36ccc88c0f969a88c07c163528910b7936c4d7be4f2216d25bc2e\"}', 'tags': [['e', 'b4d4e1de25919c3ce4f9ab6f60653cb9d819bc001c04a43d359f59bc2de2db6f'], ['p', 'b1e1185884a6d14bbfce3899cb53e8183adde642f264d0ff4f1745371e06134c']], 'sig': '43faea4b89464314c14135b0f09f8cbc2e3fd3858a8644d2b153548ac246005050d119e2249cd224bbc2def8876c038726e35db3dfd3d00a04a457341cefcb2f'}\n",
    "Event.from_dict(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2769fd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error connecting to wss://relay.damus.io: name 'websockets' is not defined\n"
     ]
    }
   ],
   "source": [
    "async def ping_relay(relay_url):\n",
    "    rtt_ms = None\n",
    "    try:\n",
    "        start = time.time()\n",
    "        async with websockets.connect(relay_url) as ws:\n",
    "            end = time.time()\n",
    "            rtt_ms = int((end - start) * 1000)\n",
    "    except KeyboardInterrupt:\n",
    "        raise KeyboardInterrupt\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to {relay_url}: {e}\")\n",
    "    return rtt_ms\n",
    "\n",
    "def fetch_relay_info(url):\n",
    "    headers = {'Accept': 'application/nostr+json'}\n",
    "    data = None\n",
    "    error = None\n",
    "    relay_url = url[6:] if url.startswith('wss://') else url[5:] if url.startswith('ws://') else url\n",
    "    try:\n",
    "        response = requests.get(f\"https://{relay_url}\", headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "        else:\n",
    "            error = response.text\n",
    "    except Exception:\n",
    "        try:\n",
    "            response = requests.get(f\"http://{relay_url}\", headers=headers, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "            else:\n",
    "                error = response.text\n",
    "        except Exception as e:\n",
    "            error = str(e)\n",
    "    return url, {'data': data, 'error': error}\n",
    "\n",
    "rtt_ms = await ping_relay('wss://relay.damus.io')\n",
    "url, info = fetch_relay_info('wss://relay.damus.io')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b99c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "relays = pd.read_csv('../data/raw/relays_url.csv')\n",
    "for url in relays['url']:\n",
    "    try:\n",
    "        async with websockets.connect(url) as ws:\n",
    "            print(f'Connected to {url}')\n",
    "    except Exception as e:\n",
    "        print(f'Failed to connect to {url}: {e}')\n",
    "    finally:\n",
    "        print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d63db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RELAY_URL = \"wss://relay.nostrdice.com\"  # Cambia con l'URL del relay reale\n",
    "RELAY_URL = \"wss://relay.boroghor.com\"  # Cambia con l'URL del relay reale\n",
    "RELAY_URL = \"wss://schnorr.me\"\n",
    "RELAY_URL = \"wss://mastodon.cloud/api/v1/streaming\"\n",
    "async def fetch_events(from_ts: int, to_ts: int):\n",
    "    events = []\n",
    "    subscription_id = str(uuid.uuid4())[:64]\n",
    "    filter_obj = {\n",
    "        # \"since\": from_ts,\n",
    "        # \"until\": to_ts,\n",
    "        # \"limit\": 10\n",
    "    }\n",
    "\n",
    "    async with websockets.connect(RELAY_URL) as ws:\n",
    "        print(f\"Connesso a {RELAY_URL}\")\n",
    "\n",
    "        req_msg = [\"REQ\", subscription_id, filter_obj]\n",
    "        await ws.send(json.dumps(req_msg))\n",
    "        print(f\"Inviato: {req_msg}\")\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                raw_message = await asyncio.wait_for(ws.recv(), timeout=30)\n",
    "                message = json.loads(raw_message)\n",
    "\n",
    "                if not isinstance(message, list):\n",
    "                    print(\"Messaggio non valido (non è un array JSON)\")\n",
    "                    continue\n",
    "\n",
    "                msg_type = message[0]\n",
    "\n",
    "                if msg_type == \"EVENT\":\n",
    "                    _, sub_id, event = message\n",
    "                    if sub_id == subscription_id:\n",
    "                        # print(f\"Ricevuto evento: {event}\")\n",
    "                        events.append(event)\n",
    "\n",
    "                elif msg_type == \"EOSE\":\n",
    "                    _, sub_id = message\n",
    "                    if sub_id == subscription_id:\n",
    "                        print(\"Fine degli eventi storici.\")\n",
    "                        break\n",
    "\n",
    "                elif msg_type == \"NOTICE\":\n",
    "                    _, notice = message\n",
    "                    print(f\"NOTICE dal relay: {notice}\")\n",
    "\n",
    "                elif msg_type == \"CLOSED\":\n",
    "                    _, sub_id, reason = message\n",
    "                    if sub_id == subscription_id:\n",
    "                        print(f\"Subscription chiusa dal relay: {reason}\")\n",
    "                        break\n",
    "\n",
    "                elif msg_type == \"OK\":\n",
    "                    _, event_id, accepted, message_str = message\n",
    "                    status = \"accettato\" if accepted else \"rifiutato\"\n",
    "                    print(f\"Evento {event_id} {status} - {message_str}\")\n",
    "\n",
    "                else:\n",
    "                    print(f\"Messaggio sconosciuto: {message}\")\n",
    "\n",
    "        except asyncio.TimeoutError:\n",
    "            print(\"Timeout: nessun messaggio ricevuto per 30 secondi.\")\n",
    "        finally:\n",
    "            close_msg = [\"CLOSE\", subscription_id]\n",
    "            await ws.send(json.dumps(close_msg))\n",
    "            print(\"Subscription chiusa.\")\n",
    "    return events\n",
    "\n",
    "# Esegui in una cella async\n",
    "async def main():\n",
    "    to_time = int(time.time())\n",
    "    from_time = to_time - 600\n",
    "    return await fetch_events(0, 1727090175)\n",
    "\n",
    "events = await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3077e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7822a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 21:19:54,979 - INFO - 🔁 RTT attempt 1/5: 744.27 ms\n",
      "2025-05-13 21:19:55,820 - INFO - 🔁 RTT attempt 2/5: 621.95 ms\n",
      "2025-05-13 21:19:56,297 - INFO - 🔁 RTT attempt 3/5: 270.14 ms\n",
      "2025-05-13 21:19:56,848 - INFO - 🔁 RTT attempt 4/5: 306.15 ms\n",
      "2025-05-13 21:19:57,460 - INFO - 🔁 RTT attempt 5/5: 306.25 ms\n",
      "2025-05-13 21:19:57,768 - INFO - ⏱️ Connecting to wss://relay.damus.io...\n",
      "2025-05-13 21:19:58,395 - INFO - 📥 Sent REQ for reading events...\n",
      "2025-05-13 21:19:58,689 - INFO - ✅ Received event or EOSE response: EVENT\n",
      "2025-05-13 21:19:58,689 - INFO - 📤 Sent EVENT to test write...\n",
      "2025-05-13 21:19:58,996 - INFO - ✅ Accepted: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 RISULTATO DEL TEST\n",
      "relay: wss://relay.damus.io\n",
      "rtt_avg_ms: 449.75\n",
      "rtt_min_ms: 270.14\n",
      "rtt_max_ms: 744.27\n",
      "rtt_stddev_ms: 217.87\n",
      "samples: 5\n",
      "can_read: True\n",
      "can_write: True\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "from event import Event\n",
    "import utils\n",
    "import uuid\n",
    "import statistics\n",
    "\n",
    "# Configura log\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Inserisci qui l'URL del relay e l'evento da testare (JSON valido)\n",
    "\n",
    "async def measure_rtt(url: str, attempts: int = 5):\n",
    "    rtts = []\n",
    "    for i in range(attempts):\n",
    "        try:\n",
    "            start = time.time()\n",
    "            async with websockets.connect(url, ping_interval=None):\n",
    "                rtt = (time.time() - start) * 1000\n",
    "                rtts.append(rtt)\n",
    "                logging.info(f\"🔁 RTT attempt {i+1}/{attempts}: {rtt:.2f} ms\")\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"❌ RTT attempt {i+1} failed: {e}\")\n",
    "    if rtts:\n",
    "        return {\n",
    "            \"rtt_avg_ms\": round(statistics.mean(rtts), 2),\n",
    "            \"rtt_min_ms\": round(min(rtts), 2),\n",
    "            \"rtt_max_ms\": round(max(rtts), 2),\n",
    "            \"rtt_stddev_ms\": round(statistics.stdev(rtts) if len(rtts) > 1 else 0.0, 2),\n",
    "            \"samples\": len(rtts)\n",
    "        }\n",
    "    else:\n",
    "        raise ConnectionError(\"All RTT attempts failed.\")\n",
    "    \n",
    "async def test_relay(url: str, event: Event):\n",
    "    try:\n",
    "        # event = event.to_dict()\n",
    "        subscription_id = str(uuid.uuid4())[:64]\n",
    "        rtt_stats = await measure_rtt(url)\n",
    "        logging.info(f\"⏱️ Connecting to {url}...\")\n",
    "        async with websockets.connect(url, ping_interval=None) as ws:\n",
    "\n",
    "            # 🟢 Test lettura: invia REQ\n",
    "            read_filter = json.dumps([\"REQ\", subscription_id, {\"limit\": 1}])\n",
    "            await ws.send(read_filter)\n",
    "            can_read = False\n",
    "            logging.info(\"📥 Sent REQ for reading events...\")\n",
    "\n",
    "            try:\n",
    "                while True:\n",
    "                    msg = await asyncio.wait_for(ws.recv(), timeout=5)\n",
    "                    data = json.loads(msg)\n",
    "                    if data[0] in [\"EVENT\", \"EOSE\"]:\n",
    "                        can_read = True\n",
    "                        logging.info(f\"✅ Received event or EOSE response: {data[0]}\")\n",
    "                        break\n",
    "            except asyncio.TimeoutError:\n",
    "                logging.warning(\"⚠️ No read response received (timeout).\")\n",
    "\n",
    "            # 🔴 Test scrittura: invia EVENT\n",
    "            event_msg = json.dumps([\"EVENT\", event])\n",
    "            await ws.send(event_msg)\n",
    "            can_write = False\n",
    "            logging.info(\"📤 Sent EVENT to test write...\")\n",
    "\n",
    "            try:\n",
    "                while True:\n",
    "                    msg = await asyncio.wait_for(ws.recv(), timeout=5)\n",
    "                    data = json.loads(msg)\n",
    "                    if data[0] == \"OK\" and data[1] == event[\"id\"]:\n",
    "                        can_write = data[2]  # true or false\n",
    "                        status = \"✅ Accepted\" if can_write else \"❌ Rejected\"\n",
    "                        logging.info(f\"{status}: {data[3]}\")\n",
    "                        break\n",
    "            except asyncio.TimeoutError:\n",
    "                logging.warning(\"⚠️ No write response received (timeout).\")\n",
    "\n",
    "            # 🔚 Chiudi la subscription\n",
    "            await ws.send(json.dumps([\"CLOSE\", subscription_id]))\n",
    "\n",
    "            return {\n",
    "                \"relay\": url,\n",
    "                **rtt_stats,\n",
    "                \"can_read\": can_read,\n",
    "                \"can_write\": can_write\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Error: {str(e)}\")\n",
    "        return {\"relay\": url, \"error\": str(e)}\n",
    "\n",
    "# Avvia il test\n",
    "if __name__ == \"__main__\":\n",
    "    relay_url = \"wss://relay.damus.io\"\n",
    "    sec, pub = utils.generate_nostr_keypair()\n",
    "    event = utils.generate_event(sec, pub, int(time.time()), 1, [], \"Test event content\")\n",
    "    result = await test_relay(relay_url, event)\n",
    "    print(\"\\n📊 RISULTATO DEL TEST\")\n",
    "    for k, v in result.items():\n",
    "        print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb8abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import concurrent.futures\n",
    "from typing import List\n",
    "import time\n",
    "from relay_metadata import RelayMetadata\n",
    "from your_module import foo  # la funzione foo che recupera i metadati del relay\n",
    "\n",
    "class Bigbrotr:\n",
    "    def __init__(self, host: str, port: int, user: str, password: str, dbname: str):\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.dbname = dbname\n",
    "        self.conn = None\n",
    "        self.cur = None\n",
    "\n",
    "    def connect(self):\n",
    "        \"\"\"Connessione al database.\"\"\"\n",
    "        self.conn = psycopg2.connect(\n",
    "            host=self.host,\n",
    "            port=self.port,\n",
    "            user=self.user,\n",
    "            password=self.password,\n",
    "            dbname=self.dbname\n",
    "        )\n",
    "        self.cur = self.conn.cursor()\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Chiude la connessione al database.\"\"\"\n",
    "        self.cur.close()\n",
    "        self.conn.close()\n",
    "\n",
    "    def fetch_relay_urls(self, limit: int, offset: int) -> List[str]:\n",
    "        \"\"\"Recupera gli URL dei relay dal database in modo paginato.\"\"\"\n",
    "        query = \"SELECT url FROM relays LIMIT %s OFFSET %s\"\n",
    "        self.cur.execute(query, (limit, offset))\n",
    "        rows = self.cur.fetchall()\n",
    "        return [row[0] for row in rows]\n",
    "\n",
    "    def insert_relay_metadata_batch(self, relay_metadata_list: List[RelayMetadata]) -> None:\n",
    "        \"\"\"Inserisce i metadati dei relay nel database in batch.\"\"\"\n",
    "        query = \"\"\"\n",
    "        INSERT INTO relay_metadata (\n",
    "            relay_url, generated_at, connection_success, nip11_success, readable, writable, \n",
    "            rtt, name, description, banner, icon, pubkey, contact, supported_nips, software, \n",
    "            version, privacy_policy, terms_of_service, limitation, extra_fields\n",
    "        ) VALUES %s\n",
    "        ON CONFLICT (relay_url, generated_at) DO NOTHING;\n",
    "        \"\"\"\n",
    "        values = [\n",
    "            (\n",
    "                rm.relay_url,\n",
    "                rm.generated_at,\n",
    "                rm.connection_success,\n",
    "                rm.nip11_success,\n",
    "                rm.readable,\n",
    "                rm.writable,\n",
    "                rm.rtt,\n",
    "                rm.name,\n",
    "                rm.description,\n",
    "                rm.banner,\n",
    "                rm.icon,\n",
    "                rm.pubkey,\n",
    "                rm.contact,\n",
    "                rm.supported_nips,\n",
    "                rm.software,\n",
    "                rm.version,\n",
    "                rm.privacy_policy,\n",
    "                rm.terms_of_service,\n",
    "                rm.limitation,\n",
    "                rm.extra_fields\n",
    "            )\n",
    "            for rm in relay_metadata_list\n",
    "        ]\n",
    "        # Inserimento in batch\n",
    "        psycopg2.extras.execute_values(self.cur, query, values)\n",
    "        self.conn.commit()\n",
    "\n",
    "def fetch_and_insert_metadata(bigbrotr: Bigbrotr, url: str) -> RelayMetadata:\n",
    "    \"\"\"Recupera i metadati del relay tramite la funzione foo.\"\"\"\n",
    "    metadata = foo(url)  # funzione che recupera i metadati dal relay\n",
    "    if metadata:\n",
    "        return metadata\n",
    "    return None\n",
    "\n",
    "def fetch_all_and_process(bigbrotr: Bigbrotr, batch_size: int = 100):\n",
    "    \"\"\"Recupera gli URL dei relay e li processa in parallelo.\"\"\"\n",
    "    limit = 100  # numero di URL da recuperare per ogni batch\n",
    "    offset = 0\n",
    "    all_metadata = []\n",
    "\n",
    "    while True:\n",
    "        relay_urls = bigbrotr.fetch_relay_urls(limit, offset)\n",
    "        if not relay_urls:\n",
    "            break  # se non ci sono più URL, interrompiamo il ciclo\n",
    "\n",
    "        # Usa un ThreadPoolExecutor per eseguire fetch_and_insert_metadata in parallelo\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            metadata_list = list(executor.map(lambda url: fetch_and_insert_metadata(bigbrotr, url), relay_urls))\n",
    "        \n",
    "        # Filtra i metad ati non None\n",
    "        metadata_list = [md for md in metadata_list if md is not None]\n",
    "        all_metadata.extend(metadata_list)\n",
    "\n",
    "        # Quando raggiungiamo il batch_size, inseriamo i metadati nel DB\n",
    "        if len(all_metadata) >= batch_size:\n",
    "            bigbrotr.insert_relay_metadata_batch(all_metadata[:batch_size])\n",
    "            all_metadata = all_metadata[batch_size:]  # Rimuove il batch appena inserito\n",
    "\n",
    "        # Aggiorna l'offset per la pagina successiva\n",
    "        offset += limit\n",
    "\n",
    "    # Se ci sono metadati rimasti che non sono stati inseriti\n",
    "    if all_metadata:\n",
    "        bigbrotr.insert_relay_metadata_batch(all_metadata)\n",
    "\n",
    "def main():\n",
    "    host = \"localhost\"\n",
    "    port = 5432\n",
    "    user = \"admin\"\n",
    "    password = \"admin\"\n",
    "    dbname = \"bigbrotr\"\n",
    "\n",
    "    bigbrotr = Bigbrotr(host, port, user, password, dbname)\n",
    "    bigbrotr.connect()\n",
    "\n",
    "    try:\n",
    "        # Avvia la raccolta e l'inserimento dei metadati\n",
    "        fetch_all_and_process(bigbrotr)\n",
    "    finally:\n",
    "        bigbrotr.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
